{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization Examples for MD Simulation\n",
    "\n",
    "This notebook demonstrates various parallelization techniques that can be applied to extend the 2-particle simulation to N particles.\n",
    "\n",
    "**Examples covered:**\n",
    "1. NumPy Vectorization\n",
    "2. Numba JIT Compilation\n",
    "3. Ensemble Parallelism\n",
    "4. GPU Acceleration (PyTorch)\n",
    "5. MPI (Message Passing Interface)\n",
    "6. Async I/O (History Recording)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Core libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "print(\"‚úÖ Core libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 1: NumPy Vectorization\n",
    "\n",
    "**Concept:** Replace Python loops with NumPy array operations for massive speedups.\n",
    "\n",
    "**Expected speedup:** 2-10x  \n",
    "**Difficulty:** ‚≠ê Easy  \n",
    "**Best for:** Small to medium systems (N < 10,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running NumPy Vectorization Benchmark...\n",
      "============================================================\n",
      "Loop version: 2.3510s\n",
      "Vectorized version: 0.0018s\n",
      "Speedup: 1298.5x\n"
     ]
    }
   ],
   "source": [
    "def update_positions_loop(positions, velocities, dt, N):\n",
    "    \"\"\"Traditional loop-based position update (SLOW).\"\"\"\n",
    "    for i in range(N):\n",
    "        positions[i] += velocities[i] * dt\n",
    "    return positions\n",
    "\n",
    "\n",
    "def update_positions_vectorized(positions, velocities, dt):\n",
    "    \"\"\"Vectorized position update using NumPy (FAST).\"\"\"\n",
    "    return positions + velocities * dt\n",
    "\n",
    "\n",
    "def benchmark_vectorization():\n",
    "    \"\"\"Compare loop vs vectorized performance.\"\"\"\n",
    "    N = 10000\n",
    "    positions = np.random.rand(N, 2) * 20.0\n",
    "    velocities = np.random.rand(N, 2) * 0.1\n",
    "    dt = 0.001\n",
    "    \n",
    "    # Loop version\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        positions_loop = update_positions_loop(positions.copy(), velocities, dt, N)\n",
    "    loop_time = time.time() - start\n",
    "    \n",
    "    # Vectorized version\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        positions_vec = update_positions_vectorized(positions.copy(), velocities, dt)\n",
    "    vec_time = time.time() - start\n",
    "    \n",
    "    print(f\"Loop version: {loop_time:.4f}s\")\n",
    "    print(f\"Vectorized version: {vec_time:.4f}s\")\n",
    "    print(f\"Speedup: {loop_time/vec_time:.1f}x\")\n",
    "\n",
    "\n",
    "# Run benchmark\n",
    "print(\"Running NumPy Vectorization Benchmark...\")\n",
    "print(\"=\" * 60)\n",
    "benchmark_vectorization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 2: Numba JIT Compilation\n",
    "\n",
    "**Concept:** Use Just-In-Time (JIT) compilation to compile Python code to machine code.\n",
    "\n",
    "**Expected speedup:** 10-100x  \n",
    "**Difficulty:** ‚≠ê‚≠ê Medium  \n",
    "**Best for:** CPU-bound computations with loops\n",
    "\n",
    "**Installation:** `pip install numba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from numba import jit, prange\n",
    "    \n",
    "    @jit(nopython=True)\n",
    "    def compute_lj_force_numba(r_vec, epsilon=1.0, sigma=1.0):\n",
    "        \"\"\"Compute Lennard-Jones force (Numba-optimized).\"\"\"\n",
    "        r = np.sqrt(r_vec[0]**2 + r_vec[1]**2)\n",
    "        if r < 1e-10:\n",
    "            return np.zeros(2)\n",
    "        \n",
    "        sr6 = (sigma / r) ** 6\n",
    "        force_mag = 24.0 * epsilon / r * (2.0 * sr6**2 - sr6)\n",
    "        r_hat = r_vec / r\n",
    "        return force_mag * r_hat\n",
    "    \n",
    "    @jit(nopython=True, parallel=True)\n",
    "    def compute_all_forces_parallel(positions, N, epsilon=1.0, sigma=1.0):\n",
    "        \"\"\"Compute all pairwise forces in parallel.\"\"\"\n",
    "        forces = np.zeros_like(positions)\n",
    "        \n",
    "        # Parallel loop over particles\n",
    "        for i in prange(N):\n",
    "            for j in range(i+1, N):\n",
    "                r_vec = positions[i] - positions[j]\n",
    "                f = compute_lj_force_numba(r_vec, epsilon, sigma)\n",
    "                forces[i] += f\n",
    "                forces[j] -= f\n",
    "        \n",
    "        return forces\n",
    "    \n",
    "    def benchmark_numba():\n",
    "        \"\"\"Benchmark Numba parallel force calculation.\"\"\"\n",
    "        N = 1000\n",
    "        positions = np.random.rand(N, 2) * 20.0\n",
    "        \n",
    "        # Warm-up (JIT compilation happens here)\n",
    "        print(\"Warming up (JIT compilation)...\")\n",
    "        _ = compute_all_forces_parallel(positions, N)\n",
    "        \n",
    "        # Benchmark\n",
    "        print(\"Running benchmark...\")\n",
    "        start = time.time()\n",
    "        for _ in range(10):\n",
    "            forces = compute_all_forces_parallel(positions, N)\n",
    "        numba_time = time.time() - start\n",
    "        \n",
    "        print(f\"Numba parallel force calculation: {numba_time:.4f}s for {N} particles\")\n",
    "        print(f\"Time per iteration: {numba_time/10:.4f}s\")\n",
    "    \n",
    "    print(\"Running Numba JIT Compilation Benchmark...\")\n",
    "    print(\"=\" * 60)\n",
    "    benchmark_numba()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ùå Numba not available.\")\n",
    "    print(\"Install with: pip install numba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 3: Ensemble Parallelism\n",
    "\n",
    "**Concept:** Run multiple independent simulations in parallel (e.g., parameter sweeps).\n",
    "\n",
    "**Expected speedup:** Nx (N = number of cores)  \n",
    "**Difficulty:** ‚≠ê Easy  \n",
    "**Best for:** Parameter studies, replica exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Ensemble Parallelism Benchmark...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def run_single_simulation(params):\n",
    "    \"\"\"Run a single simulation with given parameters.\"\"\"\n",
    "    temperature, n_steps = params\n",
    "    \n",
    "    # Simulate some work\n",
    "    np.random.seed(int(temperature * 1000))\n",
    "    positions = np.random.rand(100, 2) * 20.0\n",
    "    velocities = np.random.rand(100, 2) * 0.1 * temperature\n",
    "    \n",
    "    # Simple integration\n",
    "    dt = 0.001\n",
    "    for _ in range(n_steps):\n",
    "        positions += velocities * dt\n",
    "    \n",
    "    # Return some result\n",
    "    avg_position = np.mean(positions)\n",
    "    return temperature, avg_position\n",
    "\n",
    "\n",
    "def run_ensemble_serial(temperatures, n_steps):\n",
    "    \"\"\"Run ensemble of simulations serially.\"\"\"\n",
    "    results = []\n",
    "    for temp in temperatures:\n",
    "        result = run_single_simulation((temp, n_steps))\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_ensemble_parallel(temperatures, n_steps):\n",
    "    \"\"\"Run ensemble of simulations in parallel.\"\"\"\n",
    "    from multiprocessing import Pool\n",
    "    \n",
    "    params = [(temp, n_steps) for temp in temperatures]\n",
    "    \n",
    "    with Pool(processes=4) as pool:\n",
    "        results = pool.map(run_single_simulation, params)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def benchmark_ensemble():\n",
    "    \"\"\"Compare serial vs parallel ensemble runs.\"\"\"\n",
    "    temperatures = [100, 200, 300, 400, 500, 600, 700, 800]\n",
    "    n_steps = 1000\n",
    "    \n",
    "    # Serial\n",
    "    start = time.time()\n",
    "    results_serial = run_ensemble_serial(temperatures, n_steps)\n",
    "    serial_time = time.time() - start\n",
    "    \n",
    "    # Parallel\n",
    "    start = time.time()\n",
    "    results_parallel = run_ensemble_parallel(temperatures, n_steps)\n",
    "    parallel_time = time.time() - start\n",
    "    \n",
    "    print(f\"Serial ensemble: {serial_time:.4f}s\")\n",
    "    print(f\"Parallel ensemble: {parallel_time:.4f}s\")\n",
    "    print(f\"Speedup: {serial_time/parallel_time:.1f}x\")\n",
    "    print(f\"\\nResults (Temperature, Avg Position):\")\n",
    "    for temp, avg_pos in results_parallel[:3]:\n",
    "        print(f\"  T={temp}K: {avg_pos:.4f}\")\n",
    "\n",
    "\n",
    "# Run benchmark\n",
    "print(\"Running Ensemble Parallelism Benchmark...\")\n",
    "print(\"=\" * 60)\n",
    "benchmark_ensemble()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 4: GPU Acceleration with PyTorch\n",
    "\n",
    "**Concept:** Offload computations to GPU for massive parallelism.\n",
    "\n",
    "**Expected speedup:** 50-500x  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê Hard  \n",
    "**Best for:** Large systems (N > 10,000), long simulations\n",
    "\n",
    "**Installation:** `pip install torch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    \n",
    "    def update_positions_gpu(positions, velocities, dt):\n",
    "        \"\"\"Update positions on GPU using PyTorch.\"\"\"\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Move to GPU\n",
    "        pos_gpu = torch.tensor(positions, device=device, dtype=torch.float32)\n",
    "        vel_gpu = torch.tensor(velocities, device=device, dtype=torch.float32)\n",
    "        \n",
    "        # Compute on GPU\n",
    "        pos_gpu += vel_gpu * dt\n",
    "        \n",
    "        # Move back to CPU\n",
    "        return pos_gpu.cpu().numpy()\n",
    "    \n",
    "    def benchmark_gpu():\n",
    "        \"\"\"Benchmark GPU vs CPU for position updates.\"\"\"\n",
    "        N = 100000  # Large number for GPU to shine\n",
    "        positions = np.random.rand(N, 2).astype(np.float32) * 20.0\n",
    "        velocities = np.random.rand(N, 2).astype(np.float32) * 0.1\n",
    "        dt = 0.001\n",
    "        \n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"‚ö†Ô∏è  CUDA not available. Running on CPU only.\")\n",
    "            print(\"GPU benchmarks will not show speedup without a CUDA-capable GPU.\\n\")\n",
    "            device = torch.device('cpu')\n",
    "        else:\n",
    "            device = torch.device('cuda')\n",
    "            print(f\"‚úÖ Using GPU: {torch.cuda.get_device_name(0)}\\n\")\n",
    "        \n",
    "        # CPU version\n",
    "        start = time.time()\n",
    "        for _ in range(100):\n",
    "            pos_cpu = update_positions_vectorized(positions.copy(), velocities, dt)\n",
    "        cpu_time = time.time() - start\n",
    "        \n",
    "        # GPU version\n",
    "        pos_gpu = torch.tensor(positions, device=device)\n",
    "        vel_gpu = torch.tensor(velocities, device=device)\n",
    "        \n",
    "        # Warm-up\n",
    "        _ = pos_gpu + vel_gpu * dt\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        start = time.time()\n",
    "        for _ in range(100):\n",
    "            pos_gpu += vel_gpu * dt\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        gpu_time = time.time() - start\n",
    "        \n",
    "        print(f\"CPU (NumPy): {cpu_time:.4f}s\")\n",
    "        print(f\"GPU (PyTorch): {gpu_time:.4f}s\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"Speedup: {cpu_time/gpu_time:.1f}x\")\n",
    "        else:\n",
    "            print(\"(No GPU speedup - running on CPU)\")\n",
    "    \n",
    "    print(\"Running GPU Acceleration Benchmark...\")\n",
    "    print(\"=\" * 60)\n",
    "    benchmark_gpu()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch not available.\")\n",
    "    print(\"Install with: pip install torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 5: MPI (Message Passing Interface)\n",
    "\n",
    "**Concept:** Distribute computation across multiple nodes in a cluster.\n",
    "\n",
    "**Expected speedup:** 10-1000x (scales to 1000s of cores)  \n",
    "**Difficulty:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Expert  \n",
    "**Best for:** Very large systems (N > 100,000), HPC clusters\n",
    "\n",
    "**Installation:** Requires MPI installation + `pip install mpi4py`\n",
    "\n",
    "**Note:** MPI programs must be run from the command line with `mpiexec`, not in Jupyter notebooks. This cell will generate an example MPI script for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPI_EXAMPLE_CODE = '''\n",
    "\"\"\"MPI Example - Save this as mpi_example.py and run with:\n",
    "    mpiexec -n 4 python mpi_example.py\n",
    "\n",
    "This demonstrates basic MPI concepts for MD simulations.\n",
    "\"\"\"\n",
    "\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def mpi_hello_world():\n",
    "    \"\"\"Basic MPI: Each process prints its rank.\"\"\"\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    print(f\"Hello from rank {rank} of {size} processes\")\n",
    "    return rank, size\n",
    "\n",
    "def mpi_parallel_sum():\n",
    "    \"\"\"Demonstrate MPI reduction (sum across all processes).\"\"\"\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    local_value = rank * 10\n",
    "    total = comm.allreduce(local_value, op=MPI.SUM)\n",
    "    if rank == 0:\n",
    "        print(f\"\\\\nMPI Reduction: Sum of all ranks = {total}\")\n",
    "    return total\n",
    "\n",
    "def mpi_domain_decomposition():\n",
    "    \"\"\"Simulate domain decomposition for MD.\"\"\"\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "    \n",
    "    total_particles = 1000\n",
    "    local_n = total_particles // size\n",
    "    \n",
    "    np.random.seed(rank)\n",
    "    local_positions = np.random.rand(local_n, 3) * 20.0\n",
    "    local_velocities = np.random.rand(local_n, 3) * 0.1\n",
    "    \n",
    "    dt = 0.001\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        local_positions += local_velocities * dt\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    all_times = comm.gather(elapsed, root=0)\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\\\nMPI Domain Decomposition:\")\n",
    "        print(f\"  Total particles: {total_particles}\")\n",
    "        print(f\"  Particles per rank: {local_n}\")\n",
    "        print(f\"  Average time: {np.mean(all_times):.4f}s\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rank, size = mpi_hello_world()\n",
    "    comm = MPI.COMM_WORLD\n",
    "    comm.Barrier()\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"\\\\n\" + \"=\" * 60)\n",
    "    \n",
    "    mpi_parallel_sum()\n",
    "    comm.Barrier()\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    mpi_domain_decomposition()\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\\\nMPI examples complete!\")\n",
    "        print(\"\\\\nTo run: mpiexec -n 4 python mpi_example.py\")\n",
    "'''\n",
    "\n",
    "def show_mpi_info():\n",
    "    \"\"\"Show information about MPI and how to use it.\"\"\"\n",
    "    print(\"MPI (Message Passing Interface) Information\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        from mpi4py import MPI\n",
    "        print(\"‚úÖ mpi4py is installed!\")\n",
    "        print(f\"   MPI Version: {MPI.Get_version()}\")\n",
    "        \n",
    "        # Save example code\n",
    "        with open('mpi_example.py', 'w') as f:\n",
    "            f.write(MPI_EXAMPLE_CODE)\n",
    "        \n",
    "        print(\"\\nüìù MPI example saved to: mpi_example.py\")\n",
    "        print(\"\\nüöÄ To run MPI example:\")\n",
    "        print(\"   mpiexec -n 4 python mpi_example.py\")\n",
    "        print(\"\\nüí° This will run 4 parallel processes\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ùå mpi4py not installed\")\n",
    "        print(\"\\nüì¶ To install MPI support:\")\n",
    "        print(\"\\n   On Linux/Mac:\")\n",
    "        print(\"     sudo apt-get install libopenmpi-dev  # Ubuntu/Debian\")\n",
    "        print(\"     brew install open-mpi               # macOS\")\n",
    "        print(\"     pip install mpi4py\")\n",
    "        print(\"\\n   On Windows:\")\n",
    "        print(\"     1. Download MS-MPI from Microsoft\")\n",
    "        print(\"     2. Install MS-MPI SDK and Runtime\")\n",
    "        print(\"     3. pip install mpi4py\")\n",
    "        print(\"\\n   Or use conda:\")\n",
    "        print(\"     conda install -c conda-forge mpi4py\")\n",
    "\n",
    "# Show MPI information\n",
    "show_mpi_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 6: Async I/O (History Recording)\n",
    "\n",
    "**Concept:** Use asynchronous I/O to write trajectory data without blocking computation.\n",
    "\n",
    "**Expected speedup:** Reduces I/O bottlenecks  \n",
    "**Difficulty:** ‚≠ê‚≠ê Medium  \n",
    "**Best for:** Large trajectory files, concurrent I/O operations\n",
    "\n",
    "**Installation:** `pip install aiofiles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import asyncio\n",
    "    import aiofiles\n",
    "    \n",
    "    def save_history_sync(filename, positions, velocities, n_steps):\n",
    "        \"\"\"Save trajectory history synchronously (BLOCKING).\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            for step in range(n_steps):\n",
    "                # Simulate position update\n",
    "                positions += velocities * 0.001\n",
    "                \n",
    "                # Write to file (BLOCKS computation)\n",
    "                f.write(f\"Step {step}\\n\")\n",
    "                for i, pos in enumerate(positions):\n",
    "                    f.write(f\"  Particle {i}: {pos[0]:.6f}, {pos[1]:.6f}\\n\")\n",
    "    \n",
    "    \n",
    "    async def save_history_async(filename, positions, velocities, n_steps):\n",
    "        \"\"\"Save trajectory history asynchronously (NON-BLOCKING).\"\"\"\n",
    "        async with aiofiles.open(filename, 'w') as f:\n",
    "            for step in range(n_steps):\n",
    "                # Simulate position update\n",
    "                positions += velocities * 0.001\n",
    "                \n",
    "                # Write to file (NON-BLOCKING - allows other work)\n",
    "                await f.write(f\"Step {step}\\n\")\n",
    "                for i, pos in enumerate(positions):\n",
    "                    await f.write(f\"  Particle {i}: {pos[0]:.6f}, {pos[1]:.6f}\\n\")\n",
    "    \n",
    "    \n",
    "    def benchmark_async_io():\n",
    "        \"\"\"Compare synchronous vs asynchronous I/O.\"\"\"\n",
    "        N = 100\n",
    "        n_steps = 100\n",
    "        positions = np.random.rand(N, 2) * 20.0\n",
    "        velocities = np.random.rand(N, 2) * 0.1\n",
    "        \n",
    "        # Synchronous I/O\n",
    "        start = time.time()\n",
    "        save_history_sync('trajectory_sync.txt', positions.copy(), velocities, n_steps)\n",
    "        sync_time = time.time() - start\n",
    "        \n",
    "        # Asynchronous I/O\n",
    "        start = time.time()\n",
    "        asyncio.run(save_history_async('trajectory_async.txt', positions.copy(), velocities, n_steps))\n",
    "        async_time = time.time() - start\n",
    "        \n",
    "        print(f\"Synchronous I/O: {sync_time:.4f}s\")\n",
    "        print(f\"Asynchronous I/O: {async_time:.4f}s\")\n",
    "        print(f\"Speedup: {sync_time/async_time:.2f}x\")\n",
    "        print(f\"\\nüí° Async I/O shines when:\")\n",
    "        print(f\"   - Writing large trajectory files\")\n",
    "        print(f\"   - Doing other work while I/O happens\")\n",
    "        print(f\"   - Multiple concurrent I/O operations\")\n",
    "        \n",
    "        # Clean up\n",
    "        import os\n",
    "        try:\n",
    "            os.remove('trajectory_sync.txt')\n",
    "            os.remove('trajectory_async.txt')\n",
    "            print(\"\\n‚úÖ Temporary files cleaned up\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"Running Async I/O Benchmark...\")\n",
    "    print(\"=\" * 60)\n",
    "    benchmark_async_io()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ùå aiofiles not available.\")\n",
    "    print(\"Install with: pip install aiofiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "| Technique | Speedup | Difficulty | Best For |\n",
    "|-----------|---------|------------|----------|\n",
    "| NumPy Vectorization | 2-10x | ‚≠ê Easy | Small-medium N |\n",
    "| Numba JIT | 10-100x | ‚≠ê‚≠ê Medium | CPU-bound loops |\n",
    "| Ensemble Parallelism | Nx | ‚≠ê Easy | Parameter studies |\n",
    "| GPU (PyTorch) | 50-500x | ‚≠ê‚≠ê‚≠ê Hard | Large N, long runs |\n",
    "| MPI | 10-1000x | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Expert | HPC clusters |\n",
    "| Async I/O | Reduces I/O bottlenecks | ‚≠ê‚≠ê Medium | Large trajectory files |\n",
    "\n",
    "### Recommendations by System Size\n",
    "\n",
    "- **N < 1,000:** NumPy vectorization\n",
    "- **N = 1,000-10,000:** NumPy + Numba\n",
    "- **N = 10,000-100,000:** GPU acceleration\n",
    "- **N > 100,000:** MPI + GPU (HPC cluster)\n",
    "- **Parameter sweeps:** Ensemble parallelism\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Read:** [PARALLELIZATION_GUIDE.md](../PARALLELIZATION_GUIDE.md) for detailed theory\n",
    "2. **Install:** Optional packages from [requirements.txt](../requirements.txt)\n",
    "3. **Experiment:** Modify examples with different problem sizes\n",
    "4. **Apply:** Implement techniques when extending to N-body\n",
    "5. **Measure:** Always benchmark before and after!\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook was created with Augment Agent assistance.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
